<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">The Markovian Sommelier</h1><p class="page-description">Modeling wine reviews with a Markov chain of bigrams</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-10-15T00:00:00-05:00" itemprop="datePublished">
        Oct 15, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/jacob-rosenthal/posts/tree/master/_notebooks/2020-10-15-wine-review-generation.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/posts/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Defining-the-model">Defining the model </a></li>
<li class="toc-entry toc-h2"><a href="#Loading-the-Data">Loading the Data </a></li>
<li class="toc-entry toc-h2"><a href="#Preprocessing-the-Data">Preprocessing the Data </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Data-Structure">Data Structure </a></li>
<li class="toc-entry toc-h3"><a href="#Tokenizing">Tokenizing </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Implementing-the-model">Implementing the model </a></li>
<li class="toc-entry toc-h2"><a href="#Trying-it-out!">Trying it out! </a></li>
<li class="toc-entry toc-h2"><a href="#Conclusion">Conclusion </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-10-15-wine-review-generation.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://raw.githubusercontent.com/jtrosenthal/posts/master/images/robosomm.jpg" alt="Robot Sommelier"></p>
<p>"Rich Tannins."<br>
"Peppery finish."<br>
"Afternotes of loamy soil."</p>
<p>Who writes wine descriptions, anyways? Wine reviews are practically a genre of their own, with a specific vocabulary and its own set of phrases and that I basically never see in any other context.</p>
<p>In this projet we will make a very simple model that randomly generates new wine reviews. I will walk through each step in designing the model and implementing it!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Defining-the-model">
<a class="anchor" href="#Defining-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Defining the model<a class="anchor-link" href="#Defining-the-model"> </a>
</h2>
<p>The model we will be using is a very simple Markov chain model. First, we model each wine review as a sequence of word pairs (i.e. bigrams). Then, we create new reviews by chaining together word pairs using a single rule which is used to generate the next word given the preceding word as input. We simply look through a dataset of real wine reviews and find all occurences of the preceding word, then randomly pick one of them and use whatever word followed it in that context.</p>
<p>Here's the algorithm for generating the n-th word $w_n$ given the preceding word $w_{n-1}$ and a dataset $D$:</p>
<p>Algorithm $g(w_n | w_{n-1}, D)$:</p>
<ul>
<li>Find $O = \{o_1, o_2, \dots, o_m\}$, the set of all $m$ occurences of $w_{n-1}$ in $D$</li>
<li>Randomly choose an occurence $o_k \in O$  </li>
<li>Return the word immediately following $o_k$ in its original context</li>
</ul>
<p>Because the generation of each word depends only on the previous word, it is completely independent of all the other preceding words in the description so far. In other words, $P(w_n | w_{n-1}) = P(w_n | w_{n-1}, w_{n-2}, \dots, w_{1})$  This means that our model is a <a href="https://en.wikipedia.org/wiki/Markov_chain#Definition">Markovian process</a>. The transition probabilities between bigrams are empirically determined from our corpus.</p>
<p>Of course this is probably not going to be a great model, since it does not consider any of the context besides the immediately preceding word. But it can still give surprisingly good results, as it lets us capture many of the common two-word phrases which define the genre of wine reviews.</p>
<p>Now let's take a look at implementing this model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loading-the-Data">
<a class="anchor" href="#Loading-the-Data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loading the Data<a class="anchor-link" href="#Loading-the-Data"> </a>
</h2>
<p>Luckily, someone has already gone through the effort of creating a dataset of more than 280,000 real wine descriptions! These were scraped from <a href="https://www.winemag.com/">Wine Enthusiast</a> and the dataset is hosted on <a href="https://www.kaggle.com/zynicide/wine-reviews">Kaggle</a>. The data have been downloaded and placed in the <code>./data</code> folder. The data are split into two files.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="c1"># first load data</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./data/winemag-data-130k-v2.csv'</span><span class="p">)</span>
<span class="n">data2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./data/winemag-data_first150k.csv'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">data1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(129971, 14)
(150930, 11)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take a quick look at the datasets:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data1</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>country</th>
      <th>description</th>
      <th>designation</th>
      <th>points</th>
      <th>price</th>
      <th>province</th>
      <th>region_1</th>
      <th>region_2</th>
      <th>taster_name</th>
      <th>taster_twitter_handle</th>
      <th>title</th>
      <th>variety</th>
      <th>winery</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>Italy</td>
      <td>Aromas include tropical fruit, broom, brimston...</td>
      <td>Vulkà Bianco</td>
      <td>87</td>
      <td>NaN</td>
      <td>Sicily &amp; Sardinia</td>
      <td>Etna</td>
      <td>NaN</td>
      <td>Kerin O’Keefe</td>
      <td>@kerinokeefe</td>
      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>
      <td>White Blend</td>
      <td>Nicosia</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data2</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>country</th>
      <th>description</th>
      <th>designation</th>
      <th>points</th>
      <th>price</th>
      <th>province</th>
      <th>region_1</th>
      <th>region_2</th>
      <th>variety</th>
      <th>winery</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>US</td>
      <td>This tremendous 100% varietal wine hails from ...</td>
      <td>Martha's Vineyard</td>
      <td>96</td>
      <td>235.0</td>
      <td>California</td>
      <td>Napa Valley</td>
      <td>Napa</td>
      <td>Cabernet Sauvignon</td>
      <td>Heitz</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For this model, we are only interested in the descriptions, so let's pull those out and combine all the descriptions from both files:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">descriptions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="s2">"description"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">data2</span><span class="p">[</span><span class="s2">"description"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="c1"># strip any leading or trailing whitespace if any</span>
<span class="n">descriptions</span> <span class="o">=</span> <span class="p">[</span><span class="n">string</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">string</span> <span class="ow">in</span> <span class="n">descriptions</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Total number of descriptions: "</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">descriptions</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total number of descriptions:  280901
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take a look at a few examples:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">descriptions</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span> <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Sweet mocha and coffee notes overwhelm the bouquet of this Pinot, with red raspberry and cherry skin notes providing support. Lively acidity and a satiny texture fill the mouth, while white pepper spice lingers on the finish. 

Hints of nail polish and flavors of hard citrus candy, with grainy honey and sugar. This is not a shy Riesling; it's intense, rich with peach and apricot, and pushed just a bit too far for some tastes. 

Produced by the owners of Châteauneuf-du-Pape estate Château Mont-Redon, this is a full and fruity wine. It has a good balance between acidity and red berry fruits that give a rich character. Packed with flavor, it's ready to drink. 

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocessing-the-Data">
<a class="anchor" href="#Preprocessing-the-Data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preprocessing the Data<a class="anchor-link" href="#Preprocessing-the-Data"> </a>
</h2>
<p>Now we need to process the data to get ready for our model. But what is the best way to do this?</p>
<h3 id="Data-Structure">
<a class="anchor" href="#Data-Structure" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Structure<a class="anchor-link" href="#Data-Structure"> </a>
</h3>
<p>First we need to choose the data structure we will use. At its heart, our model relies on consectutive word pairs. So we could parse our dataset into a list of all word pairs, and then generate by filtering the list and randomly choosing.</p>
<p>However, we know that many of the word pairs will appear quite frequently! If we just parse into a list of all word pairs, we might have 100 identical entries on our list for "rich tannins." We can instead count how times a word pair occurs, and keep track of the counts of all the tokens. When it comes time to sample the next word, we can simply use probabilities proportional to the counts instead of uniformly sampling! This will let us generate words without having to process the entire set of all the token pairs in our entire dataset.</p>
<p>In python, we will implement this as a dictionary, where each key is a token. I'll call this our vocabulary. The corresponding values are dictionaries themselves containing counts of all the tokens that followed.</p>
<h3 id="Tokenizing">
<a class="anchor" href="#Tokenizing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tokenizing<a class="anchor-link" href="#Tokenizing"> </a>
</h3>
<p>Each descriptions in the dataset is a single string. We need to divide the descriptions into their individual words, so we can count the word pairs. This process is called <em>tokenization</em>, where we divide the input into a set of tokens.</p>
<p>Rather than doing this from scratch, we will use a pre-made tokenizer from Spacy. The advantage of this is that the pre-made tokenizer is smart enough to handle things like puncuation.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="c1"># use pre-made tokenizer from spacy</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"en_core_web_sm"</span><span class="p">)</span>

<span class="c1"># a dictionary will be used to hold the vocabulary</span>
<span class="c1"># each item in the vocabulary will have a counter to track which words follow it</span>
<span class="n">pair_freq</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="n">Counter</span><span class="p">)</span>

<span class="c1"># make a special end of sentence token</span>
<span class="n">end_token</span> <span class="o">=</span> <span class="s2">"END_TOKEN"</span>

<span class="c1"># process all the descriptions</span>
<span class="c1"># disabling unneeded components in the pipeline to speed it up</span>
<span class="k">for</span> <span class="n">description</span> <span class="ow">in</span> <span class="n">nlp</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">descriptions</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="p">[</span><span class="s2">"tagger"</span><span class="p">,</span> <span class="s2">"parser"</span><span class="p">,</span> <span class="s2">"ner"</span><span class="p">]):</span>
    <span class="c1"># for each token, update the counts of the following word</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">description</span><span class="p">:</span>
        <span class="c1"># get the following token</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">neighbor</span> <span class="o">=</span> <span class="n">token</span><span class="o">.</span><span class="n">nbor</span><span class="p">()</span><span class="o">.</span><span class="n">text</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
            <span class="n">neighbor</span> <span class="o">=</span> <span class="n">end_token</span>
        
        <span class="n">pair_freq</span><span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="p">][</span><span class="n">neighbor</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">pair_freq</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Total number of words:"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total number of words: 45481
CPU times: user 1min 25s, sys: 404 ms, total: 1min 26s
Wall time: 1min 27s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'robosomm_data.json'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">pair_freq</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'robosomm_data.pickle'</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">pair_freq</span><span class="p">,</span> <span class="n">handle</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our vocabulary consists of more than 45,000 unique words!</p>
<p>Let's look at some random examples of word pairs:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">token1</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span> 
    <span class="n">all_following</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">pair_freq</span><span class="p">[</span><span class="n">token1</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">token2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">all_following</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">token1</span><span class="p">,</span> <span class="n">token2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>dottings of
ripper ,
colada ,
assemblng quite
blackberry clusters
gallo salsa
Barefoot sparkling
sections that
Carpoli has
sauvage wildness
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implementing-the-model">
<a class="anchor" href="#Implementing-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementing the model<a class="anchor-link" href="#Implementing-the-model"> </a>
</h2>
<p>First, we implement our function to generate the next word. 
Because we preprocessed the data in a smart way, this is actually very simple!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">gen_next_word</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
    <span class="sd">"""Generate the next word given the preceding word"""</span>
    <span class="c1"># Get the counter for the following words</span>
    <span class="n">all_following</span> <span class="o">=</span> <span class="n">pair_freq</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
    <span class="c1"># Get the words themselves, and corresponding counts</span>
    <span class="n">following_words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">all_following</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">all_following</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
    <span class="c1"># Randomly sample the next word </span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">following_words</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">weights</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now to generate a description from scratch, we just use a loop to continuously generate the next word! The loop stops when we either hit the special end-os-sentence token, or when we reach a maximum description length.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">generate_description</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>  
    <span class="sd">"""Generate a wine descriptions given a prompt"""</span>
    <span class="n">prompt_doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
    
    <span class="c1"># set up the while loop</span>
    <span class="n">current_text</span> <span class="o">=</span> <span class="n">prompt</span>
    <span class="n">last_word</span> <span class="o">=</span> <span class="n">prompt_doc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
    <span class="n">not_end_token</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">max_desc_length</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">c</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">while</span> <span class="n">not_end_token</span> <span class="ow">and</span> <span class="n">c</span> <span class="o">&lt;</span> <span class="n">max_desc_length</span><span class="p">:</span>
        <span class="n">next_word</span> <span class="o">=</span> <span class="n">gen_next_word</span><span class="p">(</span><span class="n">last_word</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">next_word</span> <span class="o">==</span> <span class="n">end_token</span><span class="p">:</span>
            <span class="n">not_end_token</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">current_text</span> <span class="o">+=</span> <span class="s2">" "</span><span class="o">+</span><span class="n">next_word</span>
            <span class="n">last_word</span> <span class="o">=</span> <span class="n">next_word</span>
            <span class="n">c</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="k">return</span> <span class="n">current_text</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Trying-it-out!">
<a class="anchor" href="#Trying-it-out!" aria-hidden="true"><span class="octicon octicon-link"></span></a>Trying it out!<a class="anchor-link" href="#Trying-it-out!"> </a>
</h2>
<p>Now we can generate our own wine reviews! Let's look at a few examples:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">generate_description</span><span class="p">(</span><span class="s2">"A fruity merlot, with a smoky"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>"A fruity merlot, with a smoky oak . The black tea and toasty oak , apricot , allied to the next six years of lively , it 's an apéritif wine very tight and soft , it too extracted Malbec . Best now . Now–2014 ."</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">generate_description</span><span class="p">(</span><span class="s2">"A full bodied cabernet"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>"A full bodied cabernet sauvignon . It has honey , it 's a delicious , and berry fruits and rich future ."</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">generate_description</span><span class="p">(</span><span class="s2">"Spicy"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'Spicy cinnamon , it would pair with hearty mouthful of Pinot they are tougher , currants , cherries lead to the finish .'</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">generate_description</span><span class="p">(</span><span class="s2">"This wine is terrible"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'This wine is terrible flaws here . In the black fruit . It feels tight tannins , luscious and fresh and sophisticated notes , this wine offers aromas emerge with ample cherry flavors . The finish is very impressive is a bit of cherry , which offers a shame to soften . In the ripe and Mourvèdre , with suggesting wet cement , juicy and bitter , this 100 % Syrah with just yearning to say that will put in French oak flavors are certified - dimensional in the perfumes , packed with mixed with mature fruit and minerality and a final indication of'</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusion">
<a class="anchor" href="#Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion<a class="anchor-link" href="#Conclusion"> </a>
</h2>
<p>There we have it! A (very rudimentary) text generation model!</p>
<p>The descriptions certainly aren't great - I don't think any human would be fooled! However, given how rudimentary our model is, the results are surprisingly good. The sentences are mostly coherent, and they also do well at capturing the  vocabulary and phrases distinctive of the wine description genre! This shows how even the simplest model can "learn" features distinctive of the dataset it was trained on.</p>
<p>Of course we could improve on this model by using 3-grams or 4-grams instead of bigrams, which would let us capture more context. Or, we could use NLP methods that are much better than Markov chains! Recurrent neural networks, transformers, etc... Maybe we'll look at those in a future notebook.</p>
<p>In the meantime, enjoy this Markovian Sommelier!</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/posts/2020/10/15/wine-review-generation.html" hidden></a>
</article>